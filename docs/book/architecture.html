<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Architecture - The-Block Documentation</title>


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "searchindex.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">The-Block Documentation</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <i class="fa fa-spinner fa-spin"></i>
                            </div>
                        </div>
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="architecture"><a class="header" href="#architecture">Architecture</a></h1>
<p>Everything below reflects what ships in <code>main</code> today. Paths reference the exact modules so engineers can cross-check behaviour while hacking.</p>
<blockquote>
<p><strong>For newcomers:</strong> This doc is technical. Each major section starts with a plain-language explainer. If you want a gentler intro, read <a href="overview.html"><code>docs/overview.md</code></a> first.</p>
</blockquote>
<h2 id="ledger-and-consensus"><a class="header" href="#ledger-and-consensus">Ledger and Consensus</a></h2>
<blockquote>
<p><strong>Plain English:</strong> The ledger is the shared spreadsheet everyone agrees on. It tracks who owns what BLOCK and what services are owed. Blocks are like pages — every ~1 second, a new page is added containing recent transactions. "Consensus" is how all the computers (nodes) agree on which page comes next, preventing anyone from cheating.</p>
<p><strong>Key concepts:</strong></p>
<ul>
<li><strong>Regular blocks</strong>: Added every ~1 second</li>
<li><strong>Macro-blocks</strong>: Periodic checkpoints (every N blocks) that summarize state and make syncing faster</li>
<li><strong>State roots</strong>: Cryptographic fingerprints that prove what's in the ledger without showing everything</li>
</ul>
</blockquote>
<h3 id="block-format-and-state"><a class="header" href="#block-format-and-state">Block Format and State</a></h3>
<ul>
<li><code>node/src/blockchain</code> and <code>node/src/ledger_binary.rs</code> define the canonical block/ledger codecs using <code>codec::profiles</code>. Ledger snapshots embed service-badge flags, governance params, subsidy buckets, and AI-diagnostics toggles so upgrades round-trip without drift.</li>
<li>Macro-block checkpoints (<code>node/src/macro_block.rs</code>) record per-shard state roots and finalize batches of 1-second blocks for light clients and replay harnesses.</li>
<li>Genesis material stays in <code>hash_genesis.rs</code>; the compile-time assertion in <code>node/src/consensus/mod.rs</code> panics if <code>GENESIS_HASH</code> drifts from the serialized baseline.</li>
<li>Blob chain and root assembly live in <code>node/src/blob_chain.rs</code>; roots are scheduled deterministically alongside block production.</li>
</ul>
<h3 id="serialization--codecs"><a class="header" href="#serialization--codecs">Serialization &amp; Codecs</a></h3>
<ul>
<li>Canonical codecs are implemented via the <code>foundation_serialization</code> facade and the <code>codec</code> crate. Binary layouts used by the node, CLI, explorer, and metrics aggregator round-trip under these profiles.</li>
<li>JSON schemas under <code>docs/spec/</code> (for example, <code>dns_record.schema.json</code> and <code>fee_v2.schema.json</code>) document public payloads; cross-language vectors live in tests and fuzz targets (<code>fuzz/rpc</code>, <code>explorer/tests</code>).</li>
<li>Hash layout and binary struct helpers live in <code>node/src/util/binary_struct.rs</code> and <code>node/src/util/binary_codec.rs</code>. Production crates use the serialization facade; <code>serde_json</code> and <code>bincode</code> appear only in tooling.</li>
</ul>
<h3 id="proof-of-work-and-service"><a class="header" href="#proof-of-work-and-service">Proof of Work and Service</a></h3>
<ul>
<li>The hybrid PoW/PoS engine lives under <code>node/src/consensus</code>. <code>pow.rs</code> covers hash-based leaders, <code>pos.rs</code> handles stake selection, and <code>leader.rs</code> coordinates their votes before block assembly.</li>
<li>Service-aware weighting feeds through <code>node/src/service_badge.rs</code>; badge-earned weight modifies scheduler fairness plus governance quorum checks.</li>
<li><code>node/src/exec.rs</code> binds work proofs into block production, ensuring compute/storage receipts attach directly to the coinbase ledger entries.</li>
</ul>
<h3 id="sharding"><a class="header" href="#sharding">Sharding</a></h3>
<ul>
<li>Per-shard state roots are tracked and finalized in macro blocks. Inter-shard coordination, including cross-shard dependencies and reorg handling, lives in <code>node/src/blockchain/inter_shard.rs</code> with tests in <code>node/src/blockchain/tests</code>.</li>
<li>Shard identifiers and layout are defined alongside ledger codecs; helper types are under <code>ledger::address::ShardId</code>.</li>
</ul>
<h3 id="difficulty-and-proof-of-history"><a class="header" href="#difficulty-and-proof-of-history">Difficulty and Proof of History</a></h3>
<ul>
<li><code>node/src/consensus/difficulty*.rs</code> implement Kalman retargeting with clamped deltas. VDF checkpoints feed <code>node/src/poh.rs</code> so propagation remains deterministic even under adversarial timing.</li>
<li>PoH ticks emit telemetry and are replayed by <code>tests/poh.rs</code> plus the Python harness under <code>demo.py</code>.</li>
</ul>
<h3 id="macro-blocks-and-finality"><a class="header" href="#macro-blocks-and-finality">Macro Blocks and Finality</a></h3>
<ul>
<li><code>node/src/consensus/finality.rs</code> collects validator attestations, rotates stakes, and records dispute evidence in sled (<code>state/</code>).</li>
<li>The DKG helper crate <code>dkg/</code> plus <code>node/src/dkg.rs</code> coordinates committee key refresh without exposing transcripts.</li>
</ul>
<h2 id="transaction-and-execution-pipeline"><a class="header" href="#transaction-and-execution-pipeline">Transaction and Execution Pipeline</a></h2>
<blockquote>
<p><strong>Plain English:</strong> When you want to send BLOCK or use a service, you create a "transaction" — a signed message saying what you want to do. Here's the journey:</p>
<ol>
<li><strong>You sign it</strong> — Your wallet creates and signs the transaction</li>
<li><strong>It enters the mempool</strong> — The "waiting room" where transactions sit before being included in a block</li>
<li><strong>The scheduler picks it</strong> — Transactions are batched by priority (higher fees = faster)</li>
<li><strong>It gets executed</strong> — The node runs the transaction, updating balances</li>
<li><strong>A receipt is created</strong> — Proof that it happened, anchored in the ledger</li>
</ol>
<p><strong>Fee lanes</strong> are like different queues at the post office: regular, priority, special services. Each has rules and pricing.</p>
</blockquote>
<h3 id="transaction-lifecycle"><a class="header" href="#transaction-lifecycle">Transaction Lifecycle</a></h3>
<ul>
<li><code>node/src/transaction.rs</code> and <code>node/src/tx</code> encode canonical transaction envelopes shared with CLI/explorer via <code>foundation_serialization</code>. Account abstraction hooks (<code>docs/account_abstraction.md</code> equivalent) now live in <code>node/src/identity/handle_registry.rs</code> and <code>node/src/transaction/fee.rs</code>.</li>
<li>Pipeline: mempool admission → QoS lanes → scheduler → execution → receipts anchored in ledger.</li>
</ul>
<h3 id="fee-lanes-and-rebates"><a class="header" href="#fee-lanes-and-rebates">Fee Lanes and Rebates</a></h3>
<ul>
<li>Fee lanes are typed via <code>node/src/transaction::FeeLane</code> and <code>node/src/fee</code>, with rebate hooks under <code>node/src/fees</code> and <code>node/src/fee/readiness</code>. Governance controls floors through <code>governance/src/params.rs</code> and telemetry tracks enforcement (<code>fee_floor_warning_total</code>, <code>fee_floor_override_total</code>, <code>fee_floor_reject_total</code>).</li>
<li>Rebates post ledger entries that auto-apply to the submitter before consuming liquid BLOCK. Reference detail lives in <code>docs/economics_and_governance.md#fee-lanes-and-rebates</code>.</li>
</ul>
<h3 id="mempool-admission-and-eviction"><a class="header" href="#mempool-admission-and-eviction">Mempool Admission and Eviction</a></h3>
<ul>
<li>Admission and QoS live under <code>node/src/mempool/admission.rs</code>; scoring and eviction policies are in <code>node/src/mempool/scoring.rs</code>. Tests live in <code>node/src/mempool/tests</code>.</li>
<li>Fee floors and EIP‑1559‑style base fee nudges are applied per block; telemetry exposes <code>fee_floor_current</code> plus per‑lane warning/override counters, and <code>mempool.stats</code> surfaces per‑lane floors for RPC/CLI consumers.</li>
</ul>
<h3 id="scheduler-and-parallel-execution"><a class="header" href="#scheduler-and-parallel-execution">Scheduler and Parallel Execution</a></h3>
<ul>
<li><code>node/src/scheduler.rs</code> coordinates lane-aware batches with fairness timeouts. Workloads feed into <code>node/src/parallel.rs</code> so CPU-heavy tasks (GPU hashing, SNARK verification) stay deterministic.</li>
<li>The compute scheduler reuses the same fairness machinery via <code>node/src/compute_market/scheduler</code> and <code>workloads.rs</code>.</li>
</ul>
<h3 id="virtual-machine-and-wasm"><a class="header" href="#virtual-machine-and-wasm">Virtual Machine and WASM</a></h3>
<ul>
<li><code>node/src/vm</code> embeds the bytecode VM, while WASM execution and debugging helpers sit in <code>node/src/vm/debugger.rs</code> plus <code>docs/developer_handbook.md#contract-and-vm-development</code>.</li>
<li>Contracts interact with both UTXO and account space; CLI helpers live in <code>cli/src/wasm.rs</code> and <code>cli/src/contract_dev.rs</code>.</li>
</ul>
<h3 id="account-abstraction-and-identity"><a class="header" href="#account-abstraction-and-identity">Account Abstraction and Identity</a></h3>
<ul>
<li>Distributed handles, DIDs, and registry logic live in <code>node/src/identity</code>. Binary codecs for handles/DIDs ensure explorers, wallets, and RPC share the same storage bytes.</li>
<li>Light clients rely on this identity layer for DID revocation proofs and remote signer flows (<code>node/src/light_client</code>).</li>
</ul>
<h2 id="market-receipts-and-audit-trail"><a class="header" href="#market-receipts-and-audit-trail">Market Receipts and Audit Trail</a></h2>
<blockquote>
<p><strong>Plain English:</strong> Every time a market settles (storage provided, compute executed, energy delivered, ad shown), the system creates a "receipt" — permanent proof of what happened. These receipts:</p>
<ol>
<li><strong>Live on-chain</strong> — Stored in every block</li>
<li><strong>Prove consensus</strong> — Included in block hash so nodes validate them</li>
<li><strong>Drive economics</strong> — Launch Governor uses receipts to measure real market activity</li>
<li><strong>Enable auditing</strong> — Anyone can replay the chain and verify all settlements</li>
</ol>
<p><strong>Why this matters:</strong> Without receipts in consensus, malicious nodes could lie about market activity. With receipts, the entire network validates every settlement.</p>
</blockquote>
<h3 id="receipt-types-and-schema"><a class="header" href="#receipt-types-and-schema">Receipt Types and Schema</a></h3>
<p><strong>Four market receipt types exist</strong> (<code>node/src/receipts.rs</code>):</p>
<h4 id="storage-receipt"><a class="header" href="#storage-receipt">Storage Receipt</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct StorageReceipt {
    pub file_id: String,           // Unique file identifier
    pub provider: String,          // Storage provider address
    pub bytes_stored: u64,         // Total bytes in this settlement
    pub cost: u64,              // BLOCK paid to provider
    pub block_height: u64,         // When this settled
    pub duration_epochs: u32,      // How many epochs of storage
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Tracks:</strong> File storage settlements, bytes delivered, provider compensation</p>
<h4 id="compute-receipt"><a class="header" href="#compute-receipt">Compute Receipt</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct ComputeReceipt {
    pub job_id: String,            // Unique job identifier
    pub worker: String,            // Compute provider address
    pub compute_units: u64,        // Units consumed
    pub cost: u64,              // BLOCK paid to worker
    pub block_height: u64,         // When job completed
    pub proof_type: String,        // "snark", "trusted", etc.
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Tracks:</strong> Computation jobs, resource usage, verification method</p>
<h4 id="energy-receipt"><a class="header" href="#energy-receipt">Energy Receipt</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct EnergyReceipt {
    pub meter_id: String,          // Smart meter identifier
    pub provider: String,          // Energy provider address
    pub kwh_delivered: u64,        // Energy delivered (in milliwatt-hours)
    pub cost: u64,              // BLOCK paid to provider
    pub block_height: u64,         // Settlement block
    pub oracle_signature: Vec&lt;u8&gt;, // Oracle attestation
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Tracks:</strong> Energy delivery, meter readings, oracle verification</p>
<h4 id="ad-receipt"><a class="header" href="#ad-receipt">Ad Receipt</a></h4>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct AdReceipt {
    pub campaign_id: String,       // Campaign identifier
    pub publisher: String,         // Publisher address
    pub impressions: u64,          // Impressions delivered
    pub spend: u64,             // BLOCK spent by advertiser
    pub block_height: u64,         // Settlement block
    pub conversions: u32,          // Attributed conversions
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Tracks:</strong> Ad delivery, impressions, spend, attribution</p>
<h3 id="receipt-lifecycle"><a class="header" href="#receipt-lifecycle">Receipt Lifecycle</a></h3>
<p><strong>End-to-End Flow:</strong></p>
<pre><code>┌─────────────────┐
│ Market Activity │  (Storage/Compute/Energy/Ad)
│  (off-chain)    │
└────────┬────────┘
         │
         v
┌─────────────────┐
│ Market Contract │  Validates settlement
│  Settlement     │  Creates Receipt struct
└────────┬────────┘
         │
         v
┌─────────────────┐
│ Pending Buffer  │  Market holds receipts during epoch
│ (per market)    │  Accumulates all settlements
└────────┬────────┘
         │
         v
┌─────────────────┐
│ Block Assembly  │  Miner collects all pending receipts
│  (consensus)    │  Serializes via encode_receipts()
└────────┬────────┘
         │
         v
┌─────────────────┐
│ Block Hash      │  receipts_serialized included in BLAKE3
│  Calculation    │  Makes receipts consensus-critical
└────────┬────────┘
         │
         v
┌─────────────────┐
│ Block Broadcast │  Full block with receipts propagates
│  (gossip)       │  All nodes validate receipts via hash
└────────┬────────┘
         │
         v
┌─────────────────┐
│ Telemetry       │  receipt_storage_total++
│  Recording      │  receipt_bytes_per_block updated
└────────┬────────┘
         │
         v
┌─────────────────┐
│ Metrics Engine  │  Derives market utilization
│  Derivation     │  Calculates provider margins
└────────┬────────┘
         │
         v
┌─────────────────┐
│ Launch Governor │  Uses metrics for economic gates
│  Consumption    │  Adjusts subsidy allocation
└─────────────────┘
</code></pre>
<h3 id="consensus-integration"><a class="header" href="#consensus-integration">Consensus Integration</a></h3>
<p><strong>Block Hash Calculation</strong> (<code>node/src/hashlayout.rs</code>):</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct BlockEncoder&lt;'a&gt; {
    // ... existing fields ...
    pub receipts_serialized: &amp;'a [u8],  // Added December 2025
}

impl&lt;'a&gt; HashEncoder for BlockEncoder&lt;'a&gt; {
    fn encode(&amp;self, h: &amp;mut Hasher) {
        // ... hash all block fields ...
        
        // Consensus-critical: receipts affect block hash
        h.update(&amp;(self.receipts_serialized.len() as u32).to_le_bytes());
        h.update(self.receipts_serialized);
        
        // ... continue hashing ...
    }
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Why receipts are in the hash:</strong></p>
<ul>
<li>Prevents nodes from lying about market activity</li>
<li>Enables deterministic metrics derivation</li>
<li>Makes receipt tampering result in hash mismatch (rejected block)</li>
<li>Allows lightweight receipt verification (just check block hash)</li>
</ul>
<p><strong>Block Construction Pattern:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// 1. Collect receipts from all markets
let mut receipts = Vec::new();
receipts.extend(storage_market.drain_pending_receipts());
receipts.extend(compute_market.drain_pending_receipts());
receipts.extend(energy_market.drain_pending_receipts());
receipts.extend(ad_market.drain_pending_receipts());

// 2. Serialize for consensus
let receipts_bytes = block_binary::encode_receipts(&amp;receipts)?;

// 3. Build block encoder
let encoder = hashlayout::BlockEncoder {
    // ... other fields ...
    receipts_serialized: &amp;receipts_bytes,
};

// 4. Calculate hash (includes receipts)
let hash = encoder.encode(&amp;mut hasher);

// 5. Construct final block
Block {
    hash,
    receipts,  // Stored in block
    // ... other fields ...
}

### Block Validation and Transaction Verification

- `node/src/blockchain/process.rs::validate_and_apply` no longer clones `Blockchain::accounts` wholesale. It copies each account lazily the first time a transaction touches it, records the touched addresses, and emits `StateDelta` entries for only the mutated accounts so block validation keeps working set size proportional to per-block activity rather than the entire universe.
- `node/src/transaction.rs::verify_signed_tx` reuses the canonical payload bytes when building the domain-separated message, and the cache key now hashes that message plus the signing/public-key material in one pass. Deduplicated hashing removes the redundant BLAKE3 pass that previously serialized and hashed the entire transaction while still mapping each unique signed transaction to a stable `[u8; 32]` cache key.
<span class="boring">}</span></code></pre></pre>
<h3 id="receipt-serialization"><a class="header" href="#receipt-serialization">Receipt Serialization</a></h3>
<p><strong>Binary Format</strong> (<code>node/src/block_binary.rs</code>):</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn encode_receipts(receipts: &amp;[Receipt]) -&gt; EncodeResult&lt;Vec&lt;u8&gt;&gt; {
    let mut writer = Writer::with_capacity(receipts.len() * 256);
    write_receipts(&amp;mut writer, receipts)?;
    Ok(writer.finish())
}

fn write_receipts(writer: &amp;mut Writer, receipts: &amp;[Receipt]) -&gt; EncodeResult&lt;()&gt; {
    writer.write_array(receipts.len(), |array_writer| {
        for receipt in receipts {
            array_writer.item_with(|item_writer| {
                write_receipt(item_writer, receipt)
            });
        }
    });
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Determinism guarantees:</strong></p>
<ul>
<li>Fixed field order (no HashMap iteration)</li>
<li>Length-prefixed arrays</li>
<li>Platform-independent encoding (no native integers)</li>
<li>Same serialization across all nodes</li>
</ul>
<h3 id="telemetry-and-observability"><a class="header" href="#telemetry-and-observability">Telemetry and Observability</a></h3>
<p><strong>Receipt Metrics</strong> (<code>node/src/telemetry/receipts.rs</code>):</p>
<div class="table-wrapper"><table><thead><tr><th>Metric</th><th>Type</th><th>Description</th></tr></thead><tbody>
<tr><td><code>receipts_storage_total</code></td><td>Counter</td><td>Total storage receipts processed</td></tr>
<tr><td><code>receipts_compute_total</code></td><td>Counter</td><td>Total compute receipts processed</td></tr>
<tr><td><code>receipts_energy_total</code></td><td>Counter</td><td>Total energy receipts processed</td></tr>
<tr><td><code>receipts_ad_total</code></td><td>Counter</td><td>Total ad receipts processed</td></tr>
<tr><td><code>receipts_per_block</code></td><td>Gauge</td><td>Receipts in current block</td></tr>
<tr><td><code>receipts_storage_per_block</code></td><td>Gauge</td><td>Storage receipts in current block</td></tr>
<tr><td><code>receipts_compute_per_block</code></td><td>Gauge</td><td>Compute receipts in current block</td></tr>
<tr><td><code>receipts_energy_per_block</code></td><td>Gauge</td><td>Energy receipts in current block</td></tr>
<tr><td><code>receipts_ad_per_block</code></td><td>Gauge</td><td>Ad receipts in current block</td></tr>
<tr><td><code>receipt_bytes_per_block</code></td><td>Gauge</td><td>Serialized receipt size (bytes)</td></tr>
<tr><td><code>receipt_settlement_storage</code></td><td>Gauge</td><td>Storage settlement amount (BLOCK)</td></tr>
<tr><td><code>receipt_settlement_compute</code></td><td>Gauge</td><td>Compute settlement amount (BLOCK)</td></tr>
<tr><td><code>receipt_settlement_energy</code></td><td>Gauge</td><td>Energy settlement amount (BLOCK)</td></tr>
<tr><td><code>receipt_settlement_ad</code></td><td>Gauge</td><td>Ad settlement amount (BLOCK)</td></tr>
<tr><td><code>metrics_derivation_duration_ms</code></td><td>Histogram</td><td>Time to derive metrics from receipts</td></tr>
</tbody></table>
</div>
<p><strong>Usage:</strong></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(feature = "telemetry")]
{
    let serialized = block_binary::encode_receipts(&amp;block.receipts).unwrap_or_default();
    telemetry::receipts::record_receipts(&amp;block.receipts, serialized.len());
}
<span class="boring">}</span></code></pre></pre>
<h3 id="economic-metrics-derivation"><a class="header" href="#economic-metrics-derivation">Economic Metrics Derivation</a></h3>
<p><strong>Deterministic Engine</strong> (<code>node/src/economics/deterministic_metrics.rs</code>):</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn derive_market_metrics_from_chain(
    blocks: &amp;[Block],
) -&gt; MarketMetrics {
    let mut metrics = MarketMetrics::default();
    
    for block in blocks {
        for receipt in &amp;block.receipts {
            match receipt {
                Receipt::Storage(r) =&gt; {
                    metrics.storage_volume += r.bytes_stored;
                    metrics.storage_revenue += r.cost;
                },
                Receipt::Compute(r) =&gt; {
                    metrics.compute_units += r.compute_units;
                    metrics.compute_revenue += r.cost;
                },
                Receipt::Energy(r) =&gt; {
                    metrics.energy_kwh += r.kwh_delivered;
                    metrics.energy_revenue += r.cost;
                },
                Receipt::Ad(r) =&gt; {
                    metrics.ad_impressions += r.impressions;
                    metrics.ad_revenue += r.spend;
                },
            }
        }
    }
    
    // Calculate derived metrics
    metrics.storage_utilization = calculate_utilization(
        metrics.storage_volume,
        STORAGE_CAPACITY,
    );
    // ... other calculations ...
    
    metrics
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Launch Governor Integration:</strong></p>
<p>The Launch Governor consumes receipt-derived metrics:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// In launch_governor gate evaluation
let metrics = derive_market_metrics_from_chain(&amp;recent_blocks);

if metrics.storage_utilization &gt;= STORAGE_GATE_THRESHOLD
    &amp;&amp; metrics.compute_utilization &gt;= COMPUTE_GATE_THRESHOLD
    &amp;&amp; metrics.energy_utilization &gt;= ENERGY_GATE_THRESHOLD
    &amp;&amp; metrics.ad_utilization &gt;= AD_GATE_THRESHOLD
{
    // Activate economics gate
    create_intent(GateType::Economics, metrics);
}
<span class="boring">}</span></code></pre></pre>
<p>See <code>docs/operations.md#receipt-telemetry</code> for Grafana dashboard setup and alerting.</p>
<h3 id="implementation-status"><a class="header" href="#implementation-status">Implementation Status</a></h3>
<p><strong>✅ Complete (December 2025):</strong></p>
<ul>
<li>Receipt type definitions (<code>node/src/receipts.rs</code>)</li>
<li>Block serialization with receipts</li>
<li>Consensus hash integration (<code>node/src/hashlayout.rs</code>)</li>
<li>Telemetry system (<code>node/src/telemetry/receipts.rs</code>)</li>
<li>Metrics derivation engine</li>
<li>Integration tests</li>
<li>Documentation</li>
</ul>
<p><strong>⏳ In Progress:</strong></p>
<ul>
<li>BlockEncoder call site updates (manual grep + edit)</li>
<li>Market receipt emission (ad, storage, compute, energy)</li>
<li>Deployment to testnet</li>
</ul>
<p><strong>See:</strong> <code>RECEIPT_INTEGRATION_INDEX.md</code> for complete status, guides, and next steps.</p>
<h2 id="networking-and-propagation"><a class="header" href="#networking-and-propagation">Networking and Propagation</a></h2>
<blockquote>
<p><strong>Plain English:</strong> Nodes need to talk to each other to share blocks and transactions. This section covers how they find each other, establish secure connections, and gossip information across the network.</p>
<p><strong>Key concepts:</strong></p>
<ul>
<li><strong>P2P (Peer-to-Peer)</strong>: Nodes connect directly to each other, no central server</li>
<li><strong>QUIC</strong>: A fast, modern transport protocol (like TCP but better for unreliable networks)</li>
<li><strong>Gossip</strong>: How information spreads — each node tells a few others, who tell a few others, etc.</li>
<li><strong>Handshake</strong>: The initial "hello" where nodes agree on capabilities and verify identities</li>
</ul>
</blockquote>
<h3 id="p2p-handshake"><a class="header" href="#p2p-handshake">P2P Handshake</a></h3>
<ul>
<li><code>node/src/p2p/handshake.rs</code> negotiates capabilities, runtime/transport providers, and telemetry hooks. Peer identity lives in the <code>p2p_overlay</code> crate with in-house and stub adapters.</li>
<li>Capability negotiation exposes compression, service roles, and QUIC certificate fingerprints so gossip and RPC choose the right transport.</li>
<li>Handshake hellos now carry <code>gossip_addr</code> (the sender's gossip listener address); peers reply and push their chain snapshot to that address so restarts/joiners converge immediately without waiting for new blocks.</li>
<li>Adding a peer triggers an immediate handshake + hello exchange so rejoined peers resync and refresh their peer lists without waiting on a new block.</li>
<li>Inbound gossip is accepted on a non-blocking listener and processed on the blocking worker pool so chain validation cannot stall new connections. Chain sync uses explicit <code>ChainRequest</code> pulls (requesting from the local height) plus immediate snapshot pushes with exponential-backoff retries, and a periodic pull tick (default 500ms, <code>TB_P2P_CHAIN_SYNC_INTERVAL_MS</code>) to recover from missed broadcasts.</li>
<li>QUIC certificates are required for QUIC transport; if a TCP-only peer advertises an invalid QUIC cert, the handshake proceeds but QUIC metadata is ignored and the peer stays on TCP.</li>
<li>Certificate fingerprints are enforced for QUIC traffic (and for any message that includes a fingerprint); TCP fallbacks accept missing fingerprints even when a cached QUIC cert exists so mixed-transport peers can still converge.</li>
</ul>
<h3 id="p2p-wire-protocol"><a class="header" href="#p2p-wire-protocol">P2P Wire Protocol</a></h3>
<ul>
<li>Message framing and compatibility shims live under <code>node/src/p2p/wire_binary.rs</code>. Versioned encodings ensure older/minor peers interoperate; tests assert round-trip and legacy compatibility.</li>
</ul>
<h3 id="p2p-chain-synchronization"><a class="header" href="#p2p-chain-synchronization">P2P Chain Synchronization</a></h3>
<ul>
<li><strong>Messages:</strong> <code>ChainRequest { from_height }</code> (pull) and <code>Chain(Vec&lt;Block&gt;)</code> (push) live in <code>node/src/net/peer.rs</code>/<code>node/src/net/mod.rs</code>. Requests ask peers to stream the suffix beyond <code>from_height</code>; responses bundle a coalesced segment.</li>
<li><strong>Periodic pulls:</strong> A dedicated tick thread triggers chain sync every <code>TB_P2P_CHAIN_SYNC_INTERVAL_MS</code> (default 500 ms) so nodes recover from missed broadcasts without waiting for new blocks.</li>
<li><strong>Coalesced broadcast:</strong> <code>schedule_chain_broadcast()</code> batches outgoing <code>Chain</code> messages and tracks <code>last_broadcast_len</code>/<code>last_broadcast_ms</code> to avoid floods while keeping lagging peers caught up.</li>
<li><strong>Backoff + dedup:</strong> Chain pushes retry with exponential backoff (<code>send_msg_with_backoff</code>) and track watermarks so duplicate payloads are dropped early.</li>
<li><strong>PeerSet ownership:</strong> The <code>PeerSet</code> now owns the signing key used for chain sync messages and validates peer key ownership during scheduling to prevent spoofed chain pushes.</li>
</ul>
<h3 id="quic-transport"><a class="header" href="#quic-transport">QUIC Transport</a></h3>
<ul>
<li>The transport crate (<code>crates/transport</code>) exposes provider traits with backends for Quinn and s2n (feature-gated) plus an in-house stub for tests. Providers advertise capabilities to the handshake layer.</li>
<li>TLS configuration is applied per provider during instance creation (e.g., <code>apply_quinn_tls</code>, <code>apply_s2n_tls</code>), with resets ensuring only one provider’s TLS stack is active at a time.</li>
<li>Callbacks propagate connect/disconnect/handshake statistics into telemetry for dashboards and incident analysis.</li>
<li>TLS handshake timeouts are enforced on both ends: <code>ServerConfig::tls_handshake_timeout</code> and <code>ClientConfig::tls_handshake_timeout</code> guard slowloris-style stalls and are exposed via <code>TB_TLS_HANDSHAKE_TIMEOUT_MS</code>.</li>
</ul>
<h3 id="runtime-reactor-configuration"><a class="header" href="#runtime-reactor-configuration">Runtime Reactor Configuration</a></h3>
<ul>
<li><strong>Idle polling:</strong> <code>REACTOR_IDLE_POLL_MS</code> (see <code>node/src/net/inhouse/mod.rs</code>) caps the sleep between polls to keep latency predictable. For throughput-sensitive deployments, lower values reduce tail latency at the cost of CPU.</li>
<li><strong>Read/write backoff:</strong> <code>io_read_backoff_ms</code> and <code>io_write_backoff_ms</code> introduce short sleeps when readiness hints are missed; write interest is tracked explicitly to avoid busy loops on bursty peers.</li>
<li><strong>BSD kqueue hardening:</strong> <code>node/src/net/platform_bsd.rs</code> now uses level-triggered mode (removing <code>EV_CLEAR</code>) and refreshes <code>update_interest()</code> when state changes to avoid missed wakeups under load.</li>
<li><strong>Tuning guidance:</strong> Raise backoff delays if CPU is saturated by idle peers; lower them (and idle poll) for low-latency testnets. Keep telemetry on (<code>runtime_read_without_ready_total</code>, <code>runtime_write_without_ready_total</code>) to validate the chosen settings.</li>
<li><strong>Config reload fallback:</strong> <code>node/src/config.rs</code> prefers inotify/kqueue watchers, but falls back to mtime polling if filesystem events fail. Expect up to one poll interval of delay when the fallback is active.</li>
</ul>
<h3 id="overlay-and-peer-persistence"><a class="header" href="#overlay-and-peer-persistence">Overlay and Peer Persistence</a></h3>
<ul>
<li>Overlay persistence relies on <code>SimpleDb</code> namespaces (<code>node/src/net/peer.rs</code>, <code>net/overlay_store</code>). Operators migrate peer DBs via <code>scripts/migrate_overlay_store.rs</code> with guidance captured in <code>docs/operations.md#overlay-stores</code>.</li>
<li>Uptime accounting flows through <code>p2p_overlay::uptime</code>; governance reward issuances reuse the same sled-backed snapshots.</li>
</ul>
<h3 id="gossip-relay"><a class="header" href="#gossip-relay">Gossip Relay</a></h3>
<ul>
<li><code>node/src/gossip/relay.rs</code> implements TTL-bound dedup, shard-aware peer sets, and latency + reputation scoring. Fanout metrics live in <code>node/src/telemetry.rs</code> (<code>GOSSIP_*</code> series) and the relay persists shard membership so partitions recover quickly.</li>
<li>Range-boost deliveries and ANN payloads register as gossip hops, keeping mesh telemetry side-by-side with QUIC counts.</li>
<li>P2P rate limiting clamps request volume with a configurable window: <code>TB_P2P_RATE_WINDOW_SECS</code> (default 1s) controls how long counts accumulate before reset, pairing with <code>TB_P2P_MAX_PER_SEC</code>/<code>TB_P2P_MAX_BYTES_PER_SEC</code> to keep abusive peers from starving the network. Operators can widen the window for incident drills or lock it down during attacks.</li>
</ul>
<h3 id="quic-transport-1"><a class="header" href="#quic-transport-1">QUIC Transport</a></h3>
<ul>
<li>The in-house transport crate (<code>crates/transport</code>) abstracts Quinn and s2n providers. <code>node/src/net/quic.rs</code> publishes diag snapshots through RPC/CLI (<code>contract-cli net quic-stats</code>).</li>
<li>Mutual-TLS materials derive from node keys, are cached, and rotate via governance toggles. Chaos tooling lives in <code>docs/operations.md#chaos-and-fault-drills</code>.</li>
</ul>
<h3 id="localnet-and-range-boost"><a class="header" href="#localnet-and-range-boost">LocalNet and Range Boost</a></h3>
<ul>
<li>Device-to-device mesh lives in <code>node/src/localnet</code> (proximity proofs) and <code>node/src/range_boost</code> (queue, forwarder, telemetry). CLI toggles match env vars <code>TB_MESH_STATIC_PEERS</code> &amp; <code>--range-boost</code>.</li>
<li>Range boost ties into ad-market ANN snapshots: <code>node/src/ad_policy_snapshot.rs</code> persists signed JSON + <code>.sig</code> files for operator audits.</li>
</ul>
<h3 id="network-recovery-and-topologies"><a class="header" href="#network-recovery-and-topologies">Network Recovery and Topologies</a></h3>
<ul>
<li>Partition detection sits in <code>node/src/net/partition_watch.rs</code>; remediation helpers live in <code>docs/operations.md#network-recovery</code> and CLI commands under <code>cli/src/remediation.rs</code>.</li>
<li>A* routing heuristics, swarm presets, and bootstrap flow are summarized from the former <code>docs/net_a_star.md</code>, <code>docs/swarm.md</code>, <code>docs/net_bootstrap.md</code>, and <code>docs/network_topologies.md</code> into this section.</li>
</ul>
<h2 id="storage-and-state"><a class="header" href="#storage-and-state">Storage and State</a></h2>
<blockquote>
<p><strong>Plain English:</strong> The Block lets you store files in a decentralized way — like Dropbox, but no single company controls it. Files are:</p>
<ol>
<li><strong>Chunked</strong> — Split into pieces</li>
<li><strong>Encrypted</strong> — So only you can read them</li>
<li><strong>Erasure coded</strong> — Spread across multiple providers so the file survives even if some go offline</li>
<li><strong>Tracked on-chain</strong> — The ledger knows who stores what and pays them BLOCK</li>
</ol>
<p><strong>SimpleDb</strong> is our internal key-value store that handles crash-safe writes using atomic file operations.</p>
</blockquote>
<h3 id="storage-pipeline"><a class="header" href="#storage-pipeline">Storage Pipeline</a></h3>
<ul>
<li><code>node/src/storage/pipeline.rs</code> handles chunk sizing, erasure coding, encryption/compression selection, and provider placement. <code>coding/</code> supplies the compressor/erasure backends with runtime switches recorded in telemetry.</li>
<li>Manifest handling uses <code>manifest_binary.rs</code> and <code>pipeline/binary</code> for compatibility across CLI/SDK.</li>
</ul>
<h3 id="storage-market"><a class="header" href="#storage-market">Storage Market</a></h3>
<ul>
<li><code>storage_market/</code> unifies sled, RocksDB, and memory via the <code>storage_engine</code> crate and the new policy layer. Rent escrows, provider profiles, and governance overrides for redundancy all sit here.</li>
<li>Proof-of-retrievability, chunk repair, and simulator hooks now share the same store (see <code>node/src/storage/repair.rs</code>).</li>
</ul>
<h3 id="simpledb-and-storage-engines"><a class="header" href="#simpledb-and-storage-engines">SimpleDb and Storage Engines</a></h3>
<ul>
<li><code>node/src/simple_db</code> wraps the <code>storage_engine</code> traits; engines include in-house, RocksDB (feature-gated), and a memory engine for lightweight integration. Runtime selection is governed by <code>EngineConfig</code> and per-name overrides.</li>
<li>Snapshot rewrites atomically replace column families using fsync’d temp files.</li>
<li>The sled store remains in use for dedicated subsystems (for example, governance and explorer stores via the <code>sled/</code> crate), but it is not a SimpleDb backend.</li>
<li>See also <code>state/README.md</code> and <code>docs/operations.md#storage-snapshots-and-wal-management</code> for crash replay and compaction guidance.</li>
</ul>
<h3 id="snapshots-and-state-pruning"><a class="header" href="#snapshots-and-state-pruning">Snapshots and State Pruning</a></h3>
<ul>
<li>WAL + snapshot lifecycle is inside <code>node/src/storage/wal.rs</code>, <code>docs/operations.md#wal-and-snapshots</code>, and CLI commands <code>contract-cli snapshots ...</code>.</li>
<li>State pruning logic lives under <code>node/src/state_pruning.rs</code>; governance knobs guard pruning depth and compaction windows.</li>
</ul>
<h3 id="repair-and-simulation"><a class="header" href="#repair-and-simulation">Repair and Simulation</a></h3>
<ul>
<li><code>node/src/storage/repair</code> + <code>docs/operations.md#storage-repair</code> outline provider scoring, erasure thresholds, and CLI triggers.</li>
<li>Simulation harnesses (<code>docs/simulation_framework.md</code> content) now live here with references to <code>sim/</code> and <code>fuzz/</code> suites.</li>
</ul>
<h3 id="schema-migrations"><a class="header" href="#schema-migrations">Schema Migrations</a></h3>
<ul>
<li>On-disk schema changes are introduced behind version bumps and lossless migrations. Historical notes are consolidated here, in <code>docs/system_reference.md#1-5-schema-migrations</code>, and inline in code where applicable.</li>
<li>Examples: bridge header persistence (v8), DEX escrow (v9), and industrial subsidies (v10). Migrations run during startup with telemetry for progress and error handling.</li>
</ul>
<h2 id="compute-marketplace"><a class="header" href="#compute-marketplace">Compute Marketplace</a></h2>
<blockquote>
<p><strong>Plain English:</strong> Think of this as a built-in AWS marketplace where people sell compute time, and the blockchain can audit that the work actually got done.</p>
<p><strong>How it works:</strong></p>
<ol>
<li><strong>Provider offers compute</strong> — "I have a GPU, I'll run your jobs for X BLOCK per hour"</li>
<li><strong>Consumer submits a job</strong> — "Run this ML model on my data"</li>
<li><strong>Work gets done</strong> — Provider executes the job</li>
<li><strong>SNARK receipt proves it</strong> — A small cryptographic proof shows the work was done correctly, without re-running it</li>
<li><strong>BLOCK changes hands</strong> — Provider gets paid, consumer gets results</li>
</ol>
<p><strong>Key terms:</strong></p>
<ul>
<li><strong>Offer</strong>: A provider's listing (price, capacity, bond deposited)</li>
<li><strong>SNARK receipt</strong>: Proof that computation happened correctly</li>
<li><strong>SLA (Service Level Agreement)</strong>: Rules about quality/uptime; violations can lead to slashing</li>
<li><strong>Lane</strong>: Priority tier for different job types</li>
</ul>
</blockquote>
<p><strong>BlockTorch integration</strong>: The <code>blocktorch/</code> stack (metal-tensor + autograd) provides the deterministic tensor layer for ML workloads executed through the compute marketplace. BlockTorch defines the kernel set, gradient serialization, and proof-ready metadata needed for SNARK attestation and pricing via <code>ORCHARD_TENSOR_PROFILE</code>. The strategic roadmap and coordinator workflow live in <a href="ECONOMIC_PHILOSOPHY_AND_GOVERNANCE_ANALYSIS.html#part-xii-blocktorch--the-compute-framework-strategy"><code>docs/ECONOMIC_PHILOSOPHY_AND_GOVERNANCE_ANALYSIS.md</code></a>, with execution priority captured in <code>AGENTS.md §15.B.1</code>.</p>
<h3 id="offers-and-matching"><a class="header" href="#offers-and-matching">Offers and Matching</a></h3>
<ul>
<li>Computation lives under <code>node/src/compute_market</code>. Offers, bids, and receipts serialize through <code>foundation_serialization</code> and are exposed over RPC (<code>node/src/rpc/compute_market.rs</code>).</li>
<li>Providers stake bonds (<code>compute_market::Offer</code>), schedule workloads, and settle receipts via <code>compute_market::settlement</code>.</li>
</ul>
<h3 id="lane-scheduler"><a class="header" href="#lane-scheduler">Lane Scheduler</a></h3>
<ul>
<li>The matcher rotates fairness windows per lane and is backed by sled state stored under <code>state/market</code>. Lane telemetrics feed <code>match_loop_latency_seconds{lane}</code>.</li>
<li>SLA slashing is being layered atop the same scheduler per <code>AGENTS.md §15.B</code>: failed workloads will emit slash receipts anchored in BLOCK subsidy sub-ledgers, remediation dashboards (Grafana panels sourced from <code>monitoring/</code>) will highlight degraded lanes, and deterministic replay tests will cover fairness windows, starvation protection, and persisted receipts.</li>
</ul>
<h3 id="workloads-and-snark-receipts"><a class="header" href="#workloads-and-snark-receipts">Workloads and SNARK Receipts</a></h3>
<ul>
<li>Supported workloads: transcode, inference, GPU hash, SNARK. SNARK proofs now run through <code>node/src/compute_market/snark.rs</code>, which wraps the Groth16 backend, hashes wasm bytes into circuit digests, caches compiled shapes per digest, and chooses CPU/GPU provers (with telemetry exported via <code>snark_prover_latency_seconds{backend}</code> / <code>snark_prover_failure_total{backend}</code>).</li>
<li>Proof bundles carry circuit/output/witness commitments and serialized proof bytes; they are attached to SLA records in <code>compute_market::settlement</code> and surfaced over RPC via <code>compute_market.sla_history</code>.</li>
<li>Explorer ingest mirrors the same payloads: <code>contract-cli explorer sync-proofs --db explorer.db --url http://node:26658</code> streams <code>compute_market.sla_history(limit)</code> responses, persists the serialized <code>Vec&lt;ProofBundle&gt;</code> per job (<code>compute_sla_proofs</code> table), and exposes them under <code>/compute/sla/history</code> so dashboards can render fingerprints/artifacts without talking to the node.</li>
<li>Providers that advertise CUDA/ROCm GPUs (or dedicated accelerators) automatically attempt GPU proving first; failures fall back to CPU while feeding scheduler accelerator telemetry so providers can be reweighted.</li>
<li>Benchmark harnesses for the prover live under <code>node/src/compute_market/tests/prover.rs</code> so operators can compare CPU/GPU latency locally before enabling accelerators.</li>
</ul>
<h3 id="courier-and-replay"><a class="header" href="#courier-and-replay">Courier and Replay</a></h3>
<ul>
<li>Retry/courier logic (<code>node/src/compute_market/courier.rs</code>) persists inflight bundles so restarts resume outstanding work only.</li>
<li><code>docs/compute_market_courier.md</code> content moved here; CLI commands under <code>cli/src/compute.rs</code> manage the queue.</li>
</ul>
<h3 id="compute-backed-money-cbm"><a class="header" href="#compute-backed-money-cbm">Compute-backed Money (CBM)</a></h3>
<ul>
<li>CBM hooks live in <code>node/src/compute_market/cbm.rs</code>. Governance toggles lane payouts, refundable deposits, and SLA slashing (<code>compute_market::settlement::SlaOutcome</code>).</li>
</ul>
<h2 id="energy-market"><a class="header" href="#energy-market">Energy Market</a></h2>
<blockquote>
<p><strong>Plain English:</strong> The energy market lets you buy and sell real-world electricity with built-in verification. Smart meters send cryptographically signed readings to the network, which turns them into "credits" that can be settled for BLOCK.</p>
<p><strong>Example flow:</strong></p>
<div class="table-wrapper"><table><thead><tr><th>Step</th><th>What Happens</th></tr></thead><tbody>
<tr><td>1. Register</td><td>Provider signs up with capacity (e.g., 10,000 kWh) and price (e.g., 50 BLOCK/kWh)</td></tr>
<tr><td>2. Meter reading</td><td>Smart meter sends signed reading: "1,000 kWh delivered"</td></tr>
<tr><td>3. Credit created</td><td>Network verifies signature, creates an <code>EnergyCredit</code></td></tr>
<tr><td>4. Settlement</td><td>Customer settles 500 kWh → <code>EnergyReceipt</code> created, treasury fee deducted</td></tr>
<tr><td>5. Payout</td><td>Provider receives BLOCK in their account</td></tr>
</tbody></table>
</div>
<p><strong>If someone disputes a reading:</strong> A special "dispute" record is created, triggering review.</p>
</blockquote>
<ul>
<li>Energy credits live in <code>crates/energy-market</code> with the node wrapper in <code>node/src/energy.rs</code>. Providers, credits, and receipts persist in sled via <code>SimpleDb::open_named(names::ENERGY_MARKET, …)</code>; set <code>TB_ENERGY_MARKET_DIR</code> to relocate the DB. The store snapshots to bytes (<code>EnergyMarket::{to_bytes,from_bytes}</code>) on every mutation and uses the same fsync+rename discipline as other <code>SimpleDb</code> consumers so restarts replay identical state.</li>
<li>Oracle trust roots are defined in <code>config/default.toml</code> under <code>energy.provider_keys</code>. Each entry maps a provider ID to a 32-byte Ed25519 public key; reloads hot-swap the verifier registry via <code>node::energy::configure_provider_keys</code> so operators can rotate or revoke keys without restarts.</li>
<li>RPC wiring (<code>node/src/rpc/energy.rs</code>) exposes <code>energy.register_provider</code>, <code>energy.market_state</code>, <code>energy.submit_reading</code>, <code>energy.settle</code>, <code>energy.receipts</code>, <code>energy.credits</code>, <code>energy.disputes</code>, <code>energy.flag_dispute</code>, and <code>energy.resolve_dispute</code>. The CLI (<code>cli/src/energy.rs</code>) emits the same JSON schema and prints providers, receipts, credits, and disputes so oracle adapters (<code>crates/oracle-adapter</code>) and explorers stay aligned. <code>docs/testnet/ENERGY_QUICKSTART.md</code> covers bootstrap, signature validation, dispute rehearsal, and how to script <code>contract-cli energy</code> calls.</li>
<li>Governance owns <code>energy_min_stake</code>, <code>energy_oracle_timeout_blocks</code>, and <code>energy_slashing_rate_bps</code>. Proposals feed those values through the shared governance crate, latch them in <code>node/src/governance/params.rs</code>, then invoke <code>node::energy::set_governance_params</code>, so runtime hooks refresh the market config plus treasury/slashing math with no recompiles.</li>
<li>Observability: <code>energy_market</code> emits gauges (<code>energy_provider_total</code>, <code>energy_pending_credits_total</code>, <code>energy_receipt_total</code>, <code>energy_active_disputes_total</code>, <code>energy_avg_price</code>), counters (<code>energy_provider_register_total</code>, <code>energy_meter_reading_total{provider}</code>, <code>energy_settlement_total{provider}</code>, <code>energy_treasury_fee_total</code>, <code>energy_dispute_{open,resolve}_total</code>, <code>energy_kwh_traded_total</code>, <code>energy_signature_failure_total{provider,reason}</code>), histograms (<code>energy_provider_fulfillment_ms</code>, <code>oracle_reading_latency_seconds</code>), and simple health probes (<code>node::energy::check_energy_market_health</code>). Feed them into the metrics-aggregator dashboards and alert whenever pending meter credits exceed the safe envelope or signature failures spike.</li>
</ul>
<h3 id="energy-governance-and-rpc-next-tasks"><a class="header" href="#energy-governance-and-rpc-next-tasks">Energy, Governance, and RPC Next Tasks</a></h3>
<ul>
<li><strong>Governance + Params</strong>
<ul>
<li>Add proposal payloads for energy bundles (batch vs real-time settle) with <code>ParamSpec</code> + runtime hooks.</li>
<li>Wire explorer + CLI timelines so energy param changes and activation/rollback history stay visible.</li>
<li>Expand dependency graph support in proposals (deps validation in the node mirror + conflict tests).</li>
<li>Harden param persistence snapshots and rollback audits with more regression coverage.</li>
</ul>
</li>
<li><strong>Energy + Oracle</strong>
<ul>
<li>Ed25519 verification now lives inside <code>oracle-adapter</code> (<code>Ed25519SignatureVerifier</code>) with provider-key registration so adapters reject unsigned readings. Provider keys load from <code>energy.provider_keys</code> in the node config and propagate into the sled-backed verifier registry automatically. Remaining work focuses on oracle quorum/expiry policies, ledger anchoring, and advanced telemetry.</li>
<li>Add oracle quorum/expiry policy (multi-reading attestation) with richer slashing telemetry.</li>
<li>Persist energy receipts to ledger anchors or dedicated sled trees with replay tests.</li>
<li>Expand CLI/ explorer flows for provider updates (price, stake top-up) once governance exposes the payloads.</li>
</ul>
</li>
<li><strong>RPC + CLI Hardening</strong>
<ul>
<li>Add RPC auth + rate limiting specific to the <code>energy.*</code> endpoints (aligned with gateway policy).</li>
<li>Cover negative cases + structured errors for <code>energy.submit_reading</code> (bad signature, stale timestamp, wrong meter) and the new dispute endpoints.</li>
<li>Publish JSON schema snippets for energy payloads/oracle messages plus round-trip CLI tests.</li>
</ul>
</li>
<li><strong>Telemetry + Observability</strong>
<ul>
<li>Extend Grafana dashboards: provider count, pending credits, dispute trends, settlement rate, slash totals.</li>
<li>Add SLOs/alerts for oracle latency, slashing spikes, settlement stalls, and dispute backlog.</li>
<li>Wire metrics-aggregator summary endpoints so <code>/wrappers</code> and <code>/telemetry/summary</code> expose the new energy stats.</li>
</ul>
</li>
<li><strong>Network + Transport</strong>
<ul>
<li>Run QUIC chaos drills with per-provider failover simulation + fingerprint rotation tests.</li>
<li>Add handshake capability assertions in <code>node/tests</code> for the new transport metadata paths.</li>
</ul>
</li>
<li><strong>Storage + State</strong>
<ul>
<li>Mirror <code>SimpleDb</code> snapshots for energy (<code>TB_ENERGY_MARKET_DIR</code>) with fsync+atomic swap and document restore flow.</li>
<li>Ship migration drill scripts/tests for energy schema evolution (backwards compatibility).</li>
</ul>
</li>
<li><strong>Security + Supply Chain</strong>
<ul>
<li>Enforce release provenance gates for energy/oracle crates (vendor snapshot + checksums in CI).</li>
<li>Tighten oracle adapter secret hygiene (key sourcing, redaction) + boundary fuzz tests for decoding.</li>
</ul>
</li>
<li><strong>Performance + Correctness</strong>
<ul>
<li>Throughput benchmarks for meter ingestion + settlement (per-provider histograms).</li>
<li>Fuzzers for the energy binary codec, RPC param decoding, and governance activation queue.</li>
<li>Deterministic replay in CI for energy receipt reapplication across x86_64/AArch64.</li>
</ul>
</li>
<li><strong>Docs + Explorer</strong>
<ul>
<li>Explorer views: provider table, receipts timeline, fee/slash summaries, plus SQLite schema updates.</li>
<li>Expand <code>docs/testnet/ENERGY_QUICKSTART.md</code> with dispute flows + verifier integration.</li>
</ul>
</li>
<li><strong>CI + Test Suite</strong>
<ul>
<li>Stabilize the full integration suite and gate merges on: governance-param wiring, RPC energy, handshake, rate limiters, ad-market RPC.</li>
<li>Add a “fast mainnet gate” workflow that runs: unit tests + targeted integration (governance, RPC, ledger replay, transport handshake).</li>
</ul>
</li>
</ul>
<h2 id="bridges-dex-and-settlement"><a class="header" href="#bridges-dex-and-settlement">Bridges, DEX, and Settlement</a></h2>
<blockquote>
<p><strong>Plain English:</strong></p>
<ul>
<li><strong>Bridges</strong> let you move assets between The Block and other blockchains (like Ethereum). A "relayer" watches both chains and proves that a deposit on one side should unlock funds on the other.</li>
<li><strong>DEX (Decentralized Exchange)</strong> lets you trade tokens without a central exchange. Order books and "trust lines" (credit relationships between parties) are tracked on-chain.</li>
<li><strong>HTLC (Hash Time-Locked Contracts)</strong> enable atomic swaps: "I'll give you X if you reveal a secret; otherwise we both get refunds after timeout."</li>
</ul>
</blockquote>
<h3 id="token-bridges"><a class="header" href="#token-bridges">Token Bridges</a></h3>
<ul>
<li>The <code>bridges/</code> crate handles POW header verification, relayer sets, telemetry, and dispute handling. RPC wiring lives in <code>node/src/rpc/bridge.rs</code>.</li>
<li>Verified headers persist in sled (schema migration v8) and CLI commands under <code>cli/src/bridge.rs</code> manage challenge windows.</li>
<li>Release-verifier tooling now tracks relayer payload attestations, signer-set rotations, and escrow proof exports per <code>AGENTS.md §15.E</code>. Every bridge change must update <code>docs/security_and_privacy.md#release-provenance-and-supply-chain</code>, emit telemetry counters (<code>bridge_signer_rotation_total</code>, <code>bridge_partial_payment_retry_total</code>), and keep explorer dashboards aligned with the canonical snapshot JSON produced by the CLI.</li>
</ul>
<h3 id="dex-and-trust-lines"><a class="header" href="#dex-and-trust-lines">DEX and Trust Lines</a></h3>
<ul>
<li><code>node/src/dex</code> + <code>dex/</code> supply order books, trust-line routing, escrow constraints, and adapters (Uniswap/Osmosis). Trust-line state is sled-backed and streamed to explorers/CLI.</li>
<li>Deterministic replay coverage for escrow settlement and AMM invariants plus telemetry for multi-hop routing latency, escrow fulfillment, and signer rotations are required by the same <code>AGENTS.md §15.E</code> directive so dashboards and operators never diverge from node state.</li>
</ul>
<h3 id="htlc-and-cross-chain"><a class="header" href="#htlc-and-cross-chain">HTLC and Cross-Chain</a></h3>
<ul>
<li>Atomic swap primitives (<code>docs/htlc_swaps.md</code> replacement) were folded into <code>node/src/dex/htlc.rs</code> with RPC + CLI helpers. Governance tracks lane quotas and telemetry under <code>DEX_*</code> metrics.</li>
</ul>
<h2 id="gateway-and-client-access"><a class="header" href="#gateway-and-client-access">Gateway and Client Access</a></h2>
<blockquote>
<p><strong>Plain English:</strong> The gateway is the "front door" where wallets and apps talk to nodes. It handles:</p>
<ul>
<li><strong>HTTP/API requests</strong> — Apps call JSON-RPC methods to read state or submit transactions</li>
<li><strong>DNS publishing</strong> — Register <code>.block</code> domains that point to your content</li>
<li><strong>Mobile cache</strong> — Encrypted offline storage so phones work without network</li>
<li><strong>Light clients</strong> — Lightweight sync for devices that can't store the full chain</li>
</ul>
<p><strong>User story:</strong> Your wallet app connects to a gateway node. When you check your balance, the app calls an RPC method. When you send BLOCK, it submits a signed transaction. When you go offline, the mobile cache keeps recent data locally.</p>
</blockquote>
<h3 id="http-gateway"><a class="header" href="#http-gateway">HTTP Gateway</a></h3>
<ul>
<li><code>node/src/gateway/http.rs</code> uses <code>crates/httpd</code> for the router, TLS, and WebSocket upgrades. Gateways serve static content, APIs, and compute relays from the embedded storage pipeline.</li>
<li>CLI + explorer insight commands surfaced from old <code>docs/gateway.md</code> now live in <code>docs/apis_and_tooling.md#gateway</code>.</li>
</ul>
<h3 id="dns-publishing"><a class="header" href="#dns-publishing">DNS Publishing</a></h3>
<ul>
<li>DNS + <code>.block</code> records are handled by <code>node/src/gateway/dns.rs</code> with schemas archived under <code>docs/spec/dns_record.schema.json</code>.</li>
</ul>
<h3 id="dns-auctions-and-staking"><a class="header" href="#dns-auctions-and-staking">DNS Auctions and Staking</a></h3>
<ul>
<li>Gateway domain auctions use stake-backed bids and escrowed BLOCK recorded under <code>node/src/gateway/dns.rs</code> (see <code>StakeEscrowRecord</code>). RPC/CLI support deposit, withdraw, and refund flows with error codes under the same module.</li>
</ul>
<h3 id="mobile-gateway-cache"><a class="header" href="#mobile-gateway-cache">Mobile Gateway Cache</a></h3>
<ul>
<li>Mobile caches persist ChaCha20-Poly1305 encrypted blobs in sled (<code>node/src/gateway/mobile_cache.rs</code>). TTL sweeps and CLI flush commands ensure offline support without stale data.</li>
</ul>
<h3 id="light-clients"><a class="header" href="#light-clients">Light Clients</a></h3>
<ul>
<li><code>node/src/light_client</code> streams headers, DID updates, and proofs. Streaming endpoints live in <code>node/src/rpc/state_stream.rs</code> and CLI commands under <code>cli/src/light_sync.rs</code>.</li>
<li>Mobile updates plus power/bandwidth heuristics from the old <code>docs/mobile_light_client.md</code> live here and in <code>docs/apis_and_tooling.md#light-client-streaming</code>.</li>
</ul>
<h3 id="read-receipts"><a class="header" href="#read-receipts">Read Receipts</a></h3>
<ul>
<li><code>node/src/gateway/read_receipt.rs</code> records signed acknowledgements, batches them for ledger inclusion, and exposes CLI/metrics counters. Economics for <code>READ_SUB</code> live in <code>docs/economics_and_governance.md</code>.</li>
</ul>
<h2 id="launch-governor"><a class="header" href="#launch-governor">Launch Governor</a></h2>
<blockquote>
<p><strong>Plain English:</strong> The launch governor is an automated system that decides when the network is "ready" for different operational phases. Think of it like a safety system that monitors network health and only enables features when metrics look stable.</p>
<p><strong>Example:</strong> Before enabling live DNS auctions, the governor watches:</p>
<ul>
<li>Are blocks arriving at regular intervals?</li>
<li>Are peers staying connected?</li>
<li>Are test auctions completing successfully?</li>
</ul>
<p>Once these metrics hit target thresholds consistently (a "streak"), the governor transitions the network to the next phase.</p>
</blockquote>
<h3 id="gates-and-actions"><a class="header" href="#gates-and-actions">Gates and Actions</a></h3>
<p>The governor manages two primary gates:</p>
<div class="table-wrapper"><table><thead><tr><th>Gate</th><th>Purpose</th><th>Actions</th></tr></thead><tbody>
<tr><td><strong>operational</strong></td><td>Core network readiness</td><td><code>Enter</code> (enable), <code>Exit</code> (disable)</td></tr>
<tr><td><strong>naming</strong></td><td>DNS auction readiness</td><td><code>Rehearsal</code> (test mode), <code>Trade</code> (live auctions)</td></tr>
</tbody></table>
</div>
<p>Upcoming gates extend the same pattern:</p>
<div class="table-wrapper"><table><thead><tr><th>Gate (planned)</th><th>Scope</th><th>Notes</th></tr></thead><tbody>
<tr><td><strong>economics</strong></td><td>Block reward + subsidy autopilot</td><td>Shadow mode will ensure <code>NetworkIssuanceController</code> outputs count/volume/treasury metrics (<code>economics_epoch_*</code>) and the persisted <code>economics_block_reward_per_block</code> stay within bounds before runtime parameters flip.</td></tr>
<tr><td><strong>storage</strong>, <strong>compute</strong>, <strong>energy</strong>, <strong>ad</strong></td><td>Market-specific rehearsal/live toggles</td><td>Each gate will watch the telemetry already described in the respective architecture sections (utilization, margins, disputes, backlog) and will only enable “trade” mode after sustained streaks. Backlog tracked in <code>AGENTS.md §15</code>.</td></tr>
</tbody></table>
</div>
<p>Gate states progress as: <code>Inactive</code> → <code>Active</code>/<code>Rehearsal</code> → <code>Trade</code></p>
<h3 id="signal-providers"><a class="header" href="#signal-providers">Signal Providers</a></h3>
<p>The governor monitors two signal sources:</p>
<p><strong>Chain Signals</strong> (<code>ChainSample</code>):</p>
<ul>
<li><code>block_spacing</code> — Milliseconds between consecutive blocks (measures stability)</li>
<li><code>difficulty</code> — Mining difficulty trend (detects hashrate changes)</li>
<li><code>replay</code> — Success ratio of block validation replays</li>
<li><code>peer_liveness</code> — Ratio of successful peer requests vs drops</li>
<li><code>fee_band</code> — Median and P90 consumer fees</li>
</ul>
<p><strong>DNS Signals</strong> (<code>DnsSample</code>):</p>
<ul>
<li><code>txt_success</code> — TXT record publish success ratio</li>
<li><code>dispute_share</code> — Ratio of auctions ending in disputes</li>
<li><code>completion</code> — Auction completion ratio</li>
<li><code>stake_coverage_ratio</code> — Locked stake vs P90 settlement amounts</li>
<li><code>settle_durations_ms</code> — How long settlements take</li>
</ul>
<h3 id="intent-system"><a class="header" href="#intent-system">Intent System</a></h3>
<p>When gate conditions are met, the governor creates <strong>intents</strong>—timestamped records of planned state changes:</p>
<ol>
<li><strong>Intent created</strong> — Captures metrics snapshot, computes BLAKE3 hash</li>
<li><strong>Optional signing</strong> — Ed25519 signature with node key (if <code>TB_GOVERNOR_SIGN=1</code>)</li>
<li><strong>Persistence</strong> — Saved to <code>governor_db/</code> via SimpleDb</li>
<li><strong>Apply at epoch</strong> — Intents apply one epoch after creation (timelock)</li>
<li><strong>State update</strong> — Governance runtime receives parameter changes</li>
</ol>
<p>Intent records include:</p>
<ul>
<li><code>id</code> — Unique identifier (<code>{gate}-{epoch}-{seq}</code>)</li>
<li><code>params_patch</code> — JSON patch for governance parameters</li>
<li><code>snapshot_hash_hex</code> — BLAKE3 hash for auditability</li>
<li><code>metrics</code> — Summary and raw metrics that triggered the decision</li>
</ul>
<p>The RPC output now also contains an <code>economics_prev_market_metrics</code> array derived from <code>EconomicsPrevMetric</code>, and <code>contract-cli governor status</code> prints this deterministic snapshot alongside the regular <code>economics_sample</code>. This makes it easy to reconcile the governor’s JSON/RPC data with the Prometheus gauges stamped <code>economics_prev_market_metrics_{utilization,provider_margin}_ppm</code>.</p>
<h3 id="configuration"><a class="header" href="#configuration">Configuration</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Environment Variable</th><th>Purpose</th><th>Default/Guidance</th></tr></thead><tbody>
<tr><td><code>TB_GOVERNOR_ENABLED</code></td><td>Enables the background task</td><td><code>false</code> by default; <strong>must be <code>1</code> on shared testnets and mainnet</strong></td></tr>
<tr><td><code>TB_GOVERNOR_DB</code></td><td>SimpleDb path for intent history</td><td><code>governor_db/</code> relative to node data dir</td></tr>
<tr><td><code>TB_GOVERNOR_WINDOW_SECS</code></td><td>Rolling window used for signal sampling</td><td>Default <code>2 ×</code> epoch. Increase (e.g. <code>4 ×</code>) on mainnet to avoid flapping.</td></tr>
<tr><td><code>TB_GOVERNOR_SIGN</code></td><td>Emit signed decision sidecars</td><td><code>0</code> for local/dev. <strong>Set to <code>1</code> on production clusters</strong> so every intent has an Ed25519 attestation.</td></tr>
<tr><td><code>TB_NODE_KEY_HEX</code></td><td>Hex-encoded Ed25519 secret used for signing</td><td>Required when <code>TB_GOVERNOR_SIGN=1</code>.</td></tr>
</tbody></table>
</div>
<p><strong>Modes:</strong> New gates should ship in <strong>shadow mode</strong> first—emit intents + snapshots but skip <code>apply_intent</code>—until operators confirm the metrics and thresholds behave as expected. Switch to active mode by enabling <code>TB_GOVERNOR_ENABLED=1</code> (and keeping <code>apply_intent</code> wired) only after the shadow run is documented in <code>docs/operations.md</code>.</p>
<h3 id="rpc-methods"><a class="header" href="#rpc-methods">RPC Methods</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Method</th><th>Description</th></tr></thead><tbody>
<tr><td><code>governor.status</code></td><td>Current gate states, epoch, pending intents, plus the deterministic <code>EconomicsPrevMetric</code> snapshot (<code>economics_prev_market_metrics</code>) that mirrors the <code>economics_prev_market_metrics_{utilization,provider_margin}_ppm</code> gauges.</td></tr>
<tr><td><code>governor.decisions</code></td><td>Recent intent history (with <code>limit</code> param)</td></tr>
<tr><td><code>governor.snapshot</code></td><td>Load persisted decision for specific epoch</td></tr>
</tbody></table>
</div>
<h3 id="source-files"><a class="header" href="#source-files">Source Files</a></h3>
<ul>
<li><code>node/src/launch_governor/mod.rs</code> — Gate controllers, intent planning, signal evaluation</li>
<li><code>node/src/governor_snapshot.rs</code> — Snapshot persistence and signing</li>
<li><code>node/src/rpc/governor.rs</code> — RPC handlers</li>
</ul>
<h2 id="telemetry-and-instrumentation"><a class="header" href="#telemetry-and-instrumentation">Telemetry and Instrumentation</a></h2>
<blockquote>
<p><strong>Plain English:</strong> Telemetry is how operators know what's happening inside the node. The system exports:</p>
<ul>
<li><strong>Metrics</strong> — Numbers like "transactions processed per second" or "peer count"</li>
<li><strong>Logs</strong> — Text records of what happened and when</li>
<li><strong>Dashboards</strong> — Visual graphs (via Grafana) showing health over time</li>
</ul>
<p><strong>The basic pattern:</strong></p>
<ol>
<li>Node collects metrics internally</li>
<li>Metrics aggregator pulls them from multiple nodes</li>
<li>Grafana displays pretty graphs</li>
<li>Alerts fire when something looks wrong</li>
</ol>
</blockquote>
<h3 id="runtime-telemetry"><a class="header" href="#runtime-telemetry">Runtime Telemetry</a></h3>
<ul>
<li><code>node/src/telemetry.rs</code> registers every metric (TLS warnings, coding results, gossip fanout, SLA counters). CLI + aggregator share the same registry via <code>runtime::telemetry</code>.</li>
<li>Wrapper telemetry exports runtime/transport/overlay/storage/coding metadata so governance policy violations are visible.</li>
</ul>
<h3 id="metrics-aggregator"><a class="header" href="#metrics-aggregator">Metrics Aggregator</a></h3>
<ul>
<li><code>metrics-aggregator/</code> collects node metrics, correlates them, exposes TLS warning audits, bridge remediation, and governance telemetry. HTTP endpoints live in the same <code>httpd</code> router, and optional S3 uploads reuse <code>foundation_object_store</code>.</li>
</ul>
<h3 id="monitoring-stack"><a class="header" href="#monitoring-stack">Monitoring Stack</a></h3>
<ul>
<li><code>monitoring/</code> provides Grafana dashboards and Prometheus rules. JSON dashboards (e.g., <code>monitoring/compute_market_dashboard.json</code>) are kept in-tree; see <code>docs/operations.md#monitoring</code> for install steps.</li>
</ul>
<h2 id="auxiliary-services"><a class="header" href="#auxiliary-services">Auxiliary Services</a></h2>
<h3 id="service-badges"><a class="header" href="#service-badges">Service Badges</a></h3>
<ul>
<li><code>node/src/service_badge.rs</code> tracks uptime, latency, renewals, and issuance/revocation logic. Governance toggles TTL, uptime thresholds, and telemetry is emitted as <code>BADGE_*</code> counters.</li>
</ul>
<h3 id="ad-marketplace"><a class="header" href="#ad-marketplace">Ad Marketplace</a></h3>
<ul>
<li>Ad targeting is now spec'd as a multi-signal platform, not a badge-only preview. <code>crates/ad_market</code> hosts the cohort schema, privacy budget manager, uplift estimator, budget broker, and attestation logic; <code>node/src/ad_policy_snapshot.rs</code>, <code>node/src/ad_readiness.rs</code>, and <code>node/src/read_receipt.rs</code> persist/snapshot selector utilization, while <code>node/src/rpc/ad_market.rs</code>, <code>cli/src/ad_market.rs</code>, <code>cli/src/gov.rs</code>, and <code>cli/src/explorer.rs</code> surface every selector knob through the RPC/CLI/explorer stack.</li>
<li><strong>Cohort schema (<code>CohortKeyV2</code>)</strong> — Cohorts are keyed by <code>{domain,String, domain_tier:DomainTier, domain_owner?:AccountId, provider?:String, badges:Vec&lt;BadgeId&gt;, interest_tags:Vec&lt;InterestTagId&gt;, presence_bucket?:PresenceBucket, selectors_version:u16}</code> with <code>DomainTier ∈ {premium,reserved,community,unverified}</code> sourced from <code>node/src/gateway/dns.rs</code> stakes, governance-owned interest tags, and Range Boost presence buckets. Sled keys migrate via dual writes (<code>cohort_v1:*</code> + <code>cohort_v2:*</code>) plus reversible replays inside <code>node/src/ad_policy_snapshot.rs</code>/<code>node/src/ad_readiness.rs</code> so operators can downgrade if the migration stalls.</li>
<li><strong>Multi-signal auctions</strong> — <code>crates/ad_market/src/budget.rs</code> teaches the budget broker to price and pace selectors individually via <code>{selector: SelectorBidSpec {clearing_price_usd_micros, shading_factor_bps, slot_cap, max_pacing_ppm}}</code>. RPC payloads (<code>node/src/rpc/ad_market.rs</code>) and CLI helpers expose selector maps for <code>register_campaign</code>, <code>inventory</code>, <code>distribution</code>, <code>budget</code>, and <code>readiness</code> so advertisers can mix badges, interest tags, domains, and presence. Explorer summaries render per-selector revenue in <code>cli/src/explorer.rs</code>.</li>
<li><strong>Self-tuning PI controller</strong> — Budget pacing now hinges on a PI controller that runs inside each <code>CampaignBudgetState</code>. The controller tracks the relative error between <code>epoch_spend</code> and <code>epoch_target</code>, integrates it, and applies a <code>dual_price</code> adjustment once per reservation; the error zero-crossings feed a Ziegler-Nichols inspired tuner that recalculates <code>Kp/Ki</code> so the spend stays within the configured robustness window. The tuning knobs live in <code>BudgetBrokerConfig.pi_tuner</code> (fields: <code>enabled</code>, <code>kp_min</code>, <code>kp_max</code>, <code>ki_min</code>, <code>ki_max</code>, <code>ki_ratio</code>, <code>tuning_sensitivity</code>, <code>zero_cross_min_interval_micros</code>, and <code>max_integral</code>) and are normalized alongside the existing step/dual steps. <code>CampaignBudgetSnapshot.pi_controller</code> persists the controller state so deterministic replays keep the same gain history, and the resulting <code>dual_price</code>/<code>kappa</code> traces continue to surface through the existing telemetry guards.</li>
<li><strong>Proof-of-presence targeting</strong> — <code>node/src/localnet</code>, <code>node/src/range_boost</code>, and <code>node/src/service_badge.rs</code> mint <code>PresenceReceipt {beacon_id,device_key,mesh_node,location_bucket,radius_meters,confidence_bps,minted_at_micros,expires_at_micros}</code> entries that <code>crates/ad_market/src/attestation.rs</code> verifies. Receipts are cached in a privacy-safe sled store, gated by governance knobs <code>TB_PRESENCE_TTL_SECS</code>, <code>TB_PRESENCE_RADIUS_METERS</code>, and <code>TB_PRESENCE_PROOF_CACHE_SIZE</code>, and exposed through new RPCs (<code>ad_market.list_presence_cohorts</code>, <code>ad_market.reserve_presence</code>). Node <code>bin</code> logic already cancels reservations when <code>presence_badge</code> checks fail; this feature extends those hooks to the new attestation types and read-readiness rehearsal gate.</li>
<li><strong>Domain marketplace + interest ingestion</strong> — <code>node/src/gateway/dns.rs</code> emits ownership tiers and auction/intent metadata that feed the ad-policy snapshot. A governance-owned registry maps <code>.block</code> categories and premium tiers to <code>interest_tags</code>, so advertisers can reserve or exclude those audiences. Synchronization happens alongside the ad policy snapshot pruning pipeline, and readiness snapshots surface <code>domain_tier_supply_ppm</code> and <code>interest_tag_supply_ppm</code> buckets for operators. Docs (<code>docs/system_reference.md</code>, <code>docs/apis_and_tooling.md</code>) enumerate RPC validation errors for misaligned tiers/tags.</li>
<li><strong>Analytics, conversions, and uplift</strong> — <code>crates/ad_market/src/uplift.rs</code> now manages holdout cohorts per selector, exposing readiness/ROAS deltas via <code>ad_market.readiness</code>. <code>ad_market.record_conversion</code> accepts <code>value_usd_micros</code>, <code>value</code>, <code>currency_code</code>, <code>attribution_window_secs</code>, and <code>selector_weights[]</code> so advertisers can attribute conversions back to badges, interest tags, domains, and presence proofs. Readiness reports publish inventory depth, presence-proof freshness histograms, domain-tier utilization, and privacy budget status per selector, while CLI/explorer commands mirror the same aggregates.</li>
<li><strong>Privacy + governance guardrails</strong> — <code>crates/ad_market/src/privacy.rs</code> clamps selector combinations (badge + premium domain + precise presence requires explicit opt-in) and guarantees k-anonymity before releasing supply or readiness data. Violations surface via RPC errors and telemetry (<code>ad_privacy_budget_utilization_ratio</code>, <code>ad_privacy_denial_total</code>). Governance proposals (via <code>cli/src/gov.rs</code>) own selector caps, privacy budgets, interest registries, and presence TTL/radius settings.</li>
<li><strong>Observability + gate cadence</strong> — <code>metrics-aggregator/src/lib.rs</code> adds segment readiness counters (<code>ad_segment_ready_total{domain_tier,presence_bucket,interest_tag}</code>), competitiveness stats (<code>ad_auction_top_bid_usd_micros{selector}</code>, <code>ad_bid_shading_factor_bps{selector}</code>, <code>ad_auction_win_rate{selector}</code>), conversion values (<code>ad_conversion_value_total{selector}</code>), and privacy usage histograms. The aggregator exports them through <code>/wrappers</code>, Grafana panels live under <code>monitoring/ad_market_dashboard.json</code>, and <code>docs/operations.md#telemetry-wiring</code> now requires screenshots from <code>npm ci --prefix monitoring &amp;&amp; make monitor</code> whenever these metrics change. Every touch to <code>crates/ad_market</code>, <code>node/src/rpc/ad_market.rs</code>, <code>node/src/localnet</code>, <code>node/src/range_boost</code>, <code>node/src/gateway/dns.rs</code>, <code>node/src/ad_policy_snapshot.rs</code>, <code>node/src/ad_readiness.rs</code>, <code>metrics-aggregator/</code>, <code>monitoring/</code>, or the associated CLI/explorer files must rerun the full gate list (<code>just lint</code>, <code>just fmt</code>, <code>just test-fast</code>, <code>just test-full</code>, <code>cargo test -p the_block --test replay</code>, <code>cargo test -p the_block --test settlement_audit --release</code>, <code>scripts/fuzz_coverage.sh</code>) with transcripts attached per <code>AGENTS.md §0.6</code>.</li>
</ul>
<h3 id="law-enforcement-portal-and-jurisdiction-packs"><a class="header" href="#law-enforcement-portal-and-jurisdiction-packs">Law-enforcement Portal and Jurisdiction Packs</a></h3>
<ul>
<li>LE logging (<code>node/src/le_portal.rs</code>) records requests, actions, canaries, and evidence logs, with privacy redaction optional. Jurisdiction packs (<code>jurisdiction/</code>, <code>docs/security_and_privacy.md#jurisdiction-packs</code>) scope consent defaults and audit hooks.</li>
</ul>
<h3 id="range-boost-and-localnet-telemetry"><a class="header" href="#range-boost-and-localnet-telemetry">Range-Boost and LocalNet Telemetry</a></h3>
<ul>
<li>Mesh queue depth, hop latency, and fault toggles are exported via <code>node/src/range_boost</code> metrics. Operators manage peers and mesh policies through the CLI + <code>docs/operations.md#range-boost</code>.</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="system_reference.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="economics_and_governance.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="system_reference.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="economics_and_governance.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->



    </div>
    </body>
</html>
